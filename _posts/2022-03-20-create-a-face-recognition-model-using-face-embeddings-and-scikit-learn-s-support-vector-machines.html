---
layout: post
title: Create a Face Recognition Model Using Face Embeddings and Scikit Learnâ€™s Support
  Vector Machines
canonical_url: https://python.plainenglish.io/how-to-create-a-face-recognition-model-using-face-embeddings-and-scikit-learns-support-vector-8c105dc1603?source=rss-1d94e45b115------2
tag:
- face-recognition
- computer-vision
- face-verification
- support-vector-machine
- python
---

<h4>Input an image containing faces and it will output the names of all detected and recognized faces.</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/0*3dX7eUHgut3acIvb.jpg" /><figcaption>Courtesy: <a href="https://pixabay.com/photos/man-face-facial-recognition-5946820/">Image by Timisu onÂ Pixabay</a></figcaption></figure><p><strong>Introduction</strong></p><p>Face Recognition systems have many applications nowadays. From making security systems more secure to individual albums of people found in a gallery of photos, face recognition has many use-cases. In this article, I present a simple method to provide an accurate face recognition model using <a href="https://scikit-learn.org/stable/install.html">sklearn</a> and <a href="https://github.com/ageitgey/face_recognition">face_recogntition</a> Python libraries.<br>The GitHub repository for this project is here: <a href="https://github.com/pranavgupta2603/Face-Recognition"><strong>GITHUBÂ REPO</strong></a></p><p><strong>Steps<br></strong>1. <a href="#59c9">Downloading </a><a href="#59c9">sklearn, </a><a href="#59c9">face_recognition and other libraries.</a><br>2. <a href="#405d">Downloading the LFW(Labelled Faces in the Wild) training dataset.</a><br>3. <a href="#1a17">Loading the training dataset.</a><br>4. <a href="#ba93">Using </a><a href="#ba93">face_recognition python library to create face-embeddings.</a><br>5. <a href="#76df">Training the model using </a><a href="#76df">sklearn.SVM.SVC module.</a><br>6. <a href="#91a9">Predictions on the test dataset and catching â€œunknownâ€ faces.</a><br>7. <a href="#5a91">FinalÂ Remarks.</a></p><p><strong>Downloading </strong><strong>sklearn, </strong><strong>face_recognition and other libraries.</strong></p><p>I ran the commands given below on the command prompt to download the essential libraries to make a face recognition model.<br>1. pip install scikit-learn==0.24.2<br>2. pip install face-recognition==1.3.0 <br>3. pip install numpy==1.19.5<br>4. pip install opencv-python==4.5.5.62</p><p>In your python script, make sure to import these libraries likeÂ this:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/483c1c155b56c2c4f10a1962b9b1a4ea/href">https://medium.com/media/483c1c155b56c2c4f10a1962b9b1a4ea/href</a></iframe><p>glob and os are pre-installed libraries when you download PythonÂ 3.</p><p><strong>Downloading the LFW (Labelled Faces in the Wild) trainingÂ dataset</strong></p><p>You can download the dataset from this link: <a href="http://vis-www.cs.umass.edu/lfw/">LFWÂ Dataset</a>.</p><p>In the LFW webpage, scroll down until you find the â€œDownload the databaseâ€ option. Click on â€œAll images as a gzipped tar fileâ€â€Šâ€”â€Šhighlighted inÂ yellow.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/618/1*5MeHBsH8VAKy7CT8MQOHWA.png" /><figcaption>Screenshot from <a href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></figcaption></figure><p>Extract the â€œ<strong>lfw.tgz</strong>â€ file to the desired location and you will observe <strong>5,739</strong> named folders containing individual pictures.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/973/1*7fTl9E9OfAYA-79IcBb3lQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/958/1*LOCUUqr3fQjKm5GYGn-SFg.png" /><figcaption>Screenshot of the LFW Dataset in my localÂ storage</figcaption></figure><p><strong>Loading the trainingÂ dataset</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/53763fbccc1380e51dd5fc75e8678f90/href">https://medium.com/media/53763fbccc1380e51dd5fc75e8678f90/href</a></iframe><p>In the above code, we load the dataset. Make sure the main folder â€œ<strong>lfw</strong>â€ is located in the same directory in which you kept yourÂ code.</p><p>I filtered out the class folders that contained less than <strong>10</strong> pictures and took the first <strong>10</strong> pictures from the selected class folders(which contains more than <strong>10</strong> pictures). This keeps my dataset for each class non-biased.</p><p>The program also stops when the number of class folders read reaches <strong>2000â€Š</strong>â€”â€ŠI didnâ€™t want to use a lot of data, moreover, it savesÂ time.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/205/1*J1llE8k3hqLpKraVoHz2Aw.png" /><figcaption>The output of the aboveÂ code</figcaption></figure><p><strong>Using </strong><strong>face_recognition python library to create face-embeddings.</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/3737f1b65b8d3160e825991ba6170430/href">https://medium.com/media/3737f1b65b8d3160e825991ba6170430/href</a></iframe><p>For every picture in a class folder, I crop the picture to only the face of the person and append the face embedding found in <em>line 12 </em>to xâ€” the list containing the training data. The index of the class folder acts as the label of that class and is stored in a listâ€Šâ€”â€Šy.</p><p>Face embeddings are <strong>128-d</strong>(128-dimensional) vectors pertaining to facial features and are similar to the same person. For example, two face embeddings of my face would be closer to each other in a Euclidean space, compared to a face embedding of yourÂ face.</p><p>You can read more about face embeddings in the paperâ€Šâ€”â€Š<a href="https://arxiv.org/pdf/1503.03832.pdf">FaceNet: A Unified Embedding for Face Recognition and Clustering</a>.</p><p><strong>Training the model using </strong><strong>sklearn.SVM.SVC module.</strong></p><p>The training data has been created in the form ofâ€Šâ€”â€Š<br>x: <em>list of face embeddings.</em><br>y: <em>list of labels of each face embedding</em>.<br>We can now create an SVM model using sklearn which will classify these face embeddings.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4c6825cb4158f0066bbc3eccd416a863/href">https://medium.com/media/4c6825cb4158f0066bbc3eccd416a863/href</a></iframe><p>SVMâ€™s are mostly used in the <a href="https://www.learndatasci.com/glossary/binary-classification/">binary classification</a> of vectors. Therefore, I used the <a href="https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/#:~:text=One%2Dvs%2Drest%20(OvR%20for%20short%2C%20also%20referred,into%20multiple%20binary%20classification%20problems.">one-vs-rest classifying strategy</a> to incorporate SVM models for each class. In this strategy, there is one SVM model for each class that predicts a value between <strong>0</strong>(not the class) and <strong>1</strong>(is the class) when an input vector is given. You can read more about SVMs in the articleâ€Šâ€”â€Š<a href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47">Support Vector Machineâ€Šâ€”â€ŠIntroduction to Machine Learning Algorithms</a>.</p><p>The output of the full modelis the label with the highest probability from all the probabilities from theÂ models.</p><p>The picture below shows the classes the model has been trainedÂ with.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TPmoswU4tVVLree7N-ONfw.png" /><figcaption>Classes my model can predictâ€Šâ€”â€Š<strong>42</strong>Â classes</figcaption></figure><blockquote><strong><em>ğŸ’¡</em>Also learn how to perform face recognition authentication withÂ Next.js:</strong></blockquote><p><a href="https://differ.blog/p/a-demo-of-face-recognition-authentication-in-nextjs-46a363">A Demo of Face Recognition Authentication in Next.js</a></p><blockquote><em>ğŸ‘‰</em> To read more such articles, <a href="https://differ.blog/"><strong>sign up for free onÂ Differ</strong></a>.</blockquote><p><strong>Predictions on test dataset and catching â€œunknownâ€ faces</strong></p><p>The screenshot below shows the class folders I used to test my model. It contains <strong>12</strong> classes from which one class, â€œBen_Affleckâ€ was not part of the training dataset. Therefore, when the model predicts probabilities for Ben Affleckâ€™s face embedding, it would be lower probabilities (&lt;<strong>0.5</strong> ideally) as the face is unknown to the model. This information will be used to filter out unknownÂ faces.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/979/1*ACPF5-PAG-uGuwvNwKxHFA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/964/1*RibpjAeo_iecnWho5XkI2A.png" /><figcaption>Screenshot of the test dataset in my localÂ storage</figcaption></figure><p>These folders contain images of celebrities I found on the internet. We can load these images, and predict their identity using their face embeddings and the trained model. The test data can be found in the <a href="https://github.com/pranavgupta2603/Face-Recognition"><strong>Github repository</strong></a>.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/474d3a453ff0aeb6898e76475c7e85a8/href">https://medium.com/media/474d3a453ff0aeb6898e76475c7e85a8/href</a></iframe><p>The above code goes through all pictures in each class folder, finds the face embedding of each face in the pictures, and stores the face embedding in the listÂ testx.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/52552330f41fc72f2e0d522ae1236a93/href">https://medium.com/media/52552330f41fc72f2e0d522ae1236a93/href</a></iframe><p>For every face embedding in the test data, there is an array of <strong>42</strong> probabilities(the number of classes the model was trained with). By taking np.max of the probabilities, we find out the highest probability and np.argmax will find the index where the probability is theÂ highest.</p><p>If the max probability for a particular face embedding is greater than <strong>0.7</strong> then the prediction is declared as a â€œmatchâ€ and we find out the identity using class_list and classes dictionary. The threshold is taken as 0.7 with the rationale that the trend of predictions for â€œmatchedâ€ face embeddings were mostly greater thanÂ <strong>0.7</strong>.</p><p>If the max probability lies between <strong>0.5</strong> and <strong>0.7</strong> we compare the â€œinput face embeddingâ€ and the â€œrepresentative face embeddingâ€ of the predicted person. For example, the input face embedding of Ben Affleck into the model gave a probability of <strong>0.61</strong> with the identity of Amelie Mauresmo. We compare the input face embedding of Ben Affleck with the representative face embedding of Amelie Mauresmo on <em>line 29</em>. If result[0] is true then the faces match. In this case, result[0] will be false and the output will be â€œFace notÂ found!â€.</p><p>The comparison between the two face embeddings is done by calculating the <a href="https://www.cuemath.com/euclidean-distance-formula/">Euclidean distance</a> between the two vectors. As <a href="#2800">stated before</a>, face embeddings closer to each other are similar. In the above example between Ben Affleck and Amelie Mauresmo, the Euclidean distance is more than a certain threshold, hence the output will be false. <br>To learn more about calculating thresholds you can read <a href="https://stackoverflow.com/questions/22625591/how-to-calculate-threshold-value-in-eigenfaces-or-pca-algorithm-for-each-images">this on Stack Overflow</a>.</p><p>If the max probability is less than <strong>0.5</strong> then we can conclude, â€œFace notÂ found!â€.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/415/1*11yGhwjoUSR0trmckR9Slg.png" /><figcaption>The output of predictions on testÂ data</figcaption></figure><p>Here you can see every prediction on every face embedding the model came across in the test data. You can see â€œFace not found!â€ in the outputâ€Šâ€”â€Šoutput from Ben Affleckâ€™s <strong>7</strong> pictures in the testÂ dataset.</p><p>You can also see David Beckham as an output with a probability of approximately <strong>0.5144</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/946/1*j6VCmBIrvIpfzL48wCQeUA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*Ew_EwqqzBEw8vxq-eE1onA.png" /><figcaption>Left pictureâ€Šâ€”â€ŠDavid Beckhamâ€™s pictures as training data. Right pictureâ€Šâ€”â€ŠDavid Beckhamâ€™s pictures as testingÂ data.</figcaption></figure><p>The low probability is because David Beckham in the training data looked younger and did not have a beard relative to the test data. Hence, the program compares the representative face embedding of â€œDavid_Beckham_0001.jpgâ€ and the input face embedding of â€œtest1.jpgâ€ which results as true and prints the name and max probability asÂ output.</p><p>Other than that, predictions with probabilities greater than <strong>0.7</strong>, identified the faces correctly.</p><p><strong>Final Remarks</strong></p><p>I used Support Vector Machines to classify vectors because I skimmed through research papers and found that SVMs provide higher accuracy in classification compared to K-Nearest Neighbours, etc.</p><p>I hope this article gained your interest in this exciting area of computer vision and is enough to help you dive deeper into the world of artificial intelligence.</p><p><strong>References</strong></p><p><a href="http://vis-www.cs.umass.edu/~gbhuang">Gary B. Huang</a>, Manu Ramesh, <a href="http://research.yahoo.com/bouncer_user/83">Tamara Berg</a>, and <a href="http://www.cs.umass.edu/~elm">Erik Learned-Miller</a>.<br><strong>Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments.</strong><br><em>University of Massachusetts, Amherst, Technical Report 07â€“49</em>, OctoberÂ 2007.</p><p>Schroff, F., Kalenichenko, D., &amp; Philbin, J. (2015). Facenet: A unified embedding for face recognition and clustering. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 815â€“823).</p><h3>In Plain EnglishÂ ğŸš€</h3><p><em>Thank you for being a part of the </em><a href="https://plainenglish.io"><strong><em>In Plain English</em></strong></a><em> community! Before youÂ go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writerÂ ï¸ğŸ‘<strong>ï¸ï¸</strong></li><li>Follow us: <a href="https://twitter.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw"><strong>YouTube</strong></a> | <a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Discord</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href="https://cofeed.app/"><strong>CoFeed</strong></a> |Â <a href="https://differ.blog/"><strong>Differ</strong></a></li><li>More content at <a href="https://plainenglish.io"><strong>PlainEnglish.io</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8c105dc1603" width="1" height="1" alt=""><hr><p><a href="https://python.plainenglish.io/how-to-create-a-face-recognition-model-using-face-embeddings-and-scikit-learns-support-vector-8c105dc1603">Create a Face Recognition Model Using Face Embeddings and Scikit Learnâ€™s Support Vector Machines</a> was originally published in <a href="https://python.plainenglish.io">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
