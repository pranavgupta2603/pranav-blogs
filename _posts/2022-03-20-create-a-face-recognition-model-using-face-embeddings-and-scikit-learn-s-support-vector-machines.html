---
layout: post
title: Create a Face Recognition Model Using Face Embeddings and Scikit Learn’s Support
  Vector Machines
canonical_url: https://python.plainenglish.io/how-to-create-a-face-recognition-model-using-face-embeddings-and-scikit-learns-support-vector-8c105dc1603?source=rss-1d94e45b115------2
tag:
- face-recognition
- computer-vision
- face-verification
- support-vector-machine
- python
---

<h4>Input an image containing faces and it will output the names of all detected and recognized faces.</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/0*3dX7eUHgut3acIvb.jpg" /><figcaption>Courtesy: <a href="https://pixabay.com/photos/man-face-facial-recognition-5946820/">Image by Timisu on Pixabay</a></figcaption></figure><p><strong>Introduction</strong></p><p>Face Recognition systems have many applications nowadays. From making security systems more secure to individual albums of people found in a gallery of photos, face recognition has many use-cases. In this article, I present a simple method to provide an accurate face recognition model using <a href="https://scikit-learn.org/stable/install.html">sklearn</a> and <a href="https://github.com/ageitgey/face_recognition">face_recogntition</a> Python libraries.<br>The GitHub repository for this project is here: <a href="https://github.com/pranavgupta2603/Face-Recognition"><strong>GITHUB REPO</strong></a></p><p><strong>Steps<br></strong>1. <a href="#59c9">Downloading </a><a href="#59c9">sklearn, </a><a href="#59c9">face_recognition and other libraries.</a><br>2. <a href="#405d">Downloading the LFW(Labelled Faces in the Wild) training dataset.</a><br>3. <a href="#1a17">Loading the training dataset.</a><br>4. <a href="#ba93">Using </a><a href="#ba93">face_recognition python library to create face-embeddings.</a><br>5. <a href="#76df">Training the model using </a><a href="#76df">sklearn.SVM.SVC module.</a><br>6. <a href="#91a9">Predictions on the test dataset and catching “unknown” faces.</a><br>7. <a href="#5a91">Final Remarks.</a></p><p><strong>Downloading </strong><strong>sklearn, </strong><strong>face_recognition and other libraries.</strong></p><p>I ran the commands given below on the command prompt to download the essential libraries to make a face recognition model.<br>1. pip install scikit-learn==0.24.2<br>2. pip install face-recognition==1.3.0 <br>3. pip install numpy==1.19.5<br>4. pip install opencv-python==4.5.5.62</p><p>In your python script, make sure to import these libraries like this:</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/483c1c155b56c2c4f10a1962b9b1a4ea/href">https://medium.com/media/483c1c155b56c2c4f10a1962b9b1a4ea/href</a></iframe><p>glob and os are pre-installed libraries when you download Python 3.</p><p><strong>Downloading the LFW (Labelled Faces in the Wild) training dataset</strong></p><p>You can download the dataset from this link: <a href="http://vis-www.cs.umass.edu/lfw/">LFW Dataset</a>.</p><p>In the LFW webpage, scroll down until you find the “Download the database” option. Click on “All images as a gzipped tar file” — highlighted in yellow.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/618/1*5MeHBsH8VAKy7CT8MQOHWA.png" /><figcaption>Screenshot from <a href="http://vis-www.cs.umass.edu/lfw/">http://vis-www.cs.umass.edu/lfw/</a></figcaption></figure><p>Extract the “<strong>lfw.tgz</strong>” file to the desired location and you will observe <strong>5,739</strong> named folders containing individual pictures.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/973/1*7fTl9E9OfAYA-79IcBb3lQ.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/958/1*LOCUUqr3fQjKm5GYGn-SFg.png" /><figcaption>Screenshot of the LFW Dataset in my local storage</figcaption></figure><p><strong>Loading the training dataset</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/53763fbccc1380e51dd5fc75e8678f90/href">https://medium.com/media/53763fbccc1380e51dd5fc75e8678f90/href</a></iframe><p>In the above code, we load the dataset. Make sure the main folder “<strong>lfw</strong>” is located in the same directory in which you kept your code.</p><p>I filtered out the class folders that contained less than <strong>10</strong> pictures and took the first <strong>10</strong> pictures from the selected class folders(which contains more than <strong>10</strong> pictures). This keeps my dataset for each class non-biased.</p><p>The program also stops when the number of class folders read reaches <strong>2000 </strong>— I didn’t want to use a lot of data, moreover, it saves time.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/205/1*J1llE8k3hqLpKraVoHz2Aw.png" /><figcaption>The output of the above code</figcaption></figure><p><strong>Using </strong><strong>face_recognition python library to create face-embeddings.</strong></p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/3737f1b65b8d3160e825991ba6170430/href">https://medium.com/media/3737f1b65b8d3160e825991ba6170430/href</a></iframe><p>For every picture in a class folder, I crop the picture to only the face of the person and append the face embedding found in <em>line 12 </em>to x— the list containing the training data. The index of the class folder acts as the label of that class and is stored in a list — y.</p><p>Face embeddings are <strong>128-d</strong>(128-dimensional) vectors pertaining to facial features and are similar to the same person. For example, two face embeddings of my face would be closer to each other in a Euclidean space, compared to a face embedding of your face.</p><p>You can read more about face embeddings in the paper — <a href="https://arxiv.org/pdf/1503.03832.pdf">FaceNet: A Unified Embedding for Face Recognition and Clustering</a>.</p><p><strong>Training the model using </strong><strong>sklearn.SVM.SVC module.</strong></p><p>The training data has been created in the form of — <br>x: <em>list of face embeddings.</em><br>y: <em>list of labels of each face embedding</em>.<br>We can now create an SVM model using sklearn which will classify these face embeddings.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/4c6825cb4158f0066bbc3eccd416a863/href">https://medium.com/media/4c6825cb4158f0066bbc3eccd416a863/href</a></iframe><p>SVM’s are mostly used in the <a href="https://www.learndatasci.com/glossary/binary-classification/">binary classification</a> of vectors. Therefore, I used the <a href="https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/#:~:text=One%2Dvs%2Drest%20(OvR%20for%20short%2C%20also%20referred,into%20multiple%20binary%20classification%20problems.">one-vs-rest classifying strategy</a> to incorporate SVM models for each class. In this strategy, there is one SVM model for each class that predicts a value between <strong>0</strong>(not the class) and <strong>1</strong>(is the class) when an input vector is given. You can read more about SVMs in the article — <a href="https://towardsdatascience.com/support-vector-machine-introduction-to-machine-learning-algorithms-934a444fca47">Support Vector Machine — Introduction to Machine Learning Algorithms</a>.</p><p>The output of the full modelis the label with the highest probability from all the probabilities from the models.</p><p>The picture below shows the classes the model has been trained with.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*TPmoswU4tVVLree7N-ONfw.png" /><figcaption>Classes my model can predict — <strong>42</strong> classes</figcaption></figure><blockquote><strong><em>💡</em>Also learn how to perform face recognition authentication with Next.js:</strong></blockquote><p><a href="https://differ.blog/p/a-demo-of-face-recognition-authentication-in-nextjs-46a363">A Demo of Face Recognition Authentication in Next.js</a></p><blockquote><em>👉</em> To read more such articles, <a href="https://differ.blog/"><strong>sign up for free on Differ</strong></a>.</blockquote><p><strong>Predictions on test dataset and catching “unknown” faces</strong></p><p>The screenshot below shows the class folders I used to test my model. It contains <strong>12</strong> classes from which one class, “Ben_Affleck” was not part of the training dataset. Therefore, when the model predicts probabilities for Ben Affleck’s face embedding, it would be lower probabilities (&lt;<strong>0.5</strong> ideally) as the face is unknown to the model. This information will be used to filter out unknown faces.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/979/1*ACPF5-PAG-uGuwvNwKxHFA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/964/1*RibpjAeo_iecnWho5XkI2A.png" /><figcaption>Screenshot of the test dataset in my local storage</figcaption></figure><p>These folders contain images of celebrities I found on the internet. We can load these images, and predict their identity using their face embeddings and the trained model. The test data can be found in the <a href="https://github.com/pranavgupta2603/Face-Recognition"><strong>Github repository</strong></a>.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/474d3a453ff0aeb6898e76475c7e85a8/href">https://medium.com/media/474d3a453ff0aeb6898e76475c7e85a8/href</a></iframe><p>The above code goes through all pictures in each class folder, finds the face embedding of each face in the pictures, and stores the face embedding in the list testx.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/52552330f41fc72f2e0d522ae1236a93/href">https://medium.com/media/52552330f41fc72f2e0d522ae1236a93/href</a></iframe><p>For every face embedding in the test data, there is an array of <strong>42</strong> probabilities(the number of classes the model was trained with). By taking np.max of the probabilities, we find out the highest probability and np.argmax will find the index where the probability is the highest.</p><p>If the max probability for a particular face embedding is greater than <strong>0.7</strong> then the prediction is declared as a “match” and we find out the identity using class_list and classes dictionary. The threshold is taken as 0.7 with the rationale that the trend of predictions for “matched” face embeddings were mostly greater than <strong>0.7</strong>.</p><p>If the max probability lies between <strong>0.5</strong> and <strong>0.7</strong> we compare the “input face embedding” and the “representative face embedding” of the predicted person. For example, the input face embedding of Ben Affleck into the model gave a probability of <strong>0.61</strong> with the identity of Amelie Mauresmo. We compare the input face embedding of Ben Affleck with the representative face embedding of Amelie Mauresmo on <em>line 29</em>. If result[0] is true then the faces match. In this case, result[0] will be false and the output will be “Face not found!”.</p><p>The comparison between the two face embeddings is done by calculating the <a href="https://www.cuemath.com/euclidean-distance-formula/">Euclidean distance</a> between the two vectors. As <a href="#2800">stated before</a>, face embeddings closer to each other are similar. In the above example between Ben Affleck and Amelie Mauresmo, the Euclidean distance is more than a certain threshold, hence the output will be false. <br>To learn more about calculating thresholds you can read <a href="https://stackoverflow.com/questions/22625591/how-to-calculate-threshold-value-in-eigenfaces-or-pca-algorithm-for-each-images">this on Stack Overflow</a>.</p><p>If the max probability is less than <strong>0.5</strong> then we can conclude, “Face not found!”.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/415/1*11yGhwjoUSR0trmckR9Slg.png" /><figcaption>The output of predictions on test data</figcaption></figure><p>Here you can see every prediction on every face embedding the model came across in the test data. You can see “Face not found!” in the output — output from Ben Affleck’s <strong>7</strong> pictures in the test dataset.</p><p>You can also see David Beckham as an output with a probability of approximately <strong>0.5144</strong>.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/946/1*j6VCmBIrvIpfzL48wCQeUA.png" /></figure><figure><img alt="" src="https://cdn-images-1.medium.com/max/960/1*Ew_EwqqzBEw8vxq-eE1onA.png" /><figcaption>Left picture — David Beckham’s pictures as training data. Right picture — David Beckham’s pictures as testing data.</figcaption></figure><p>The low probability is because David Beckham in the training data looked younger and did not have a beard relative to the test data. Hence, the program compares the representative face embedding of “David_Beckham_0001.jpg” and the input face embedding of “test1.jpg” which results as true and prints the name and max probability as output.</p><p>Other than that, predictions with probabilities greater than <strong>0.7</strong>, identified the faces correctly.</p><p><strong>Final Remarks</strong></p><p>I used Support Vector Machines to classify vectors because I skimmed through research papers and found that SVMs provide higher accuracy in classification compared to K-Nearest Neighbours, etc.</p><p>I hope this article gained your interest in this exciting area of computer vision and is enough to help you dive deeper into the world of artificial intelligence.</p><p><strong>References</strong></p><p><a href="http://vis-www.cs.umass.edu/~gbhuang">Gary B. Huang</a>, Manu Ramesh, <a href="http://research.yahoo.com/bouncer_user/83">Tamara Berg</a>, and <a href="http://www.cs.umass.edu/~elm">Erik Learned-Miller</a>.<br><strong>Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments.</strong><br><em>University of Massachusetts, Amherst, Technical Report 07–49</em>, October 2007.</p><p>Schroff, F., Kalenichenko, D., &amp; Philbin, J. (2015). Facenet: A unified embedding for face recognition and clustering. In <em>Proceedings of the IEEE conference on computer vision and pattern recognition</em> (pp. 815–823).</p><h3>In Plain English 🚀</h3><p><em>Thank you for being a part of the </em><a href="https://plainenglish.io"><strong><em>In Plain English</em></strong></a><em> community! Before you go:</em></p><ul><li>Be sure to <strong>clap</strong> and <strong>follow</strong> the writer ️👏<strong>️️</strong></li><li>Follow us: <a href="https://twitter.com/inPlainEngHQ"><strong>X</strong></a> | <a href="https://www.linkedin.com/company/inplainenglish/"><strong>LinkedIn</strong></a> | <a href="https://www.youtube.com/channel/UCtipWUghju290NWcn8jhyAw"><strong>YouTube</strong></a> | <a href="https://discord.gg/in-plain-english-709094664682340443"><strong>Discord</strong></a> | <a href="https://newsletter.plainenglish.io/"><strong>Newsletter</strong></a></li><li>Visit our other platforms: <a href="https://cofeed.app/"><strong>CoFeed</strong></a> | <a href="https://differ.blog/"><strong>Differ</strong></a></li><li>More content at <a href="https://plainenglish.io"><strong>PlainEnglish.io</strong></a></li></ul><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=8c105dc1603" width="1" height="1" alt=""><hr><p><a href="https://python.plainenglish.io/how-to-create-a-face-recognition-model-using-face-embeddings-and-scikit-learns-support-vector-8c105dc1603">Create a Face Recognition Model Using Face Embeddings and Scikit Learn’s Support Vector Machines</a> was originally published in <a href="https://python.plainenglish.io">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
