---
layout: post
title: Automating the Game Wordle Using Computer Vision
canonical_url: https://python.plainenglish.io/automating-game-wordle-using-computer-vision-a84010de92b7?source=rss-1d94e45b115------2
tag:
- wordle
- computer-vision
- python
- artificial-intelligence
- automate
---

<h4>Screenshot a partially-filled <a href="https://www.powerlanguage.co.uk/wordle/">Wordle</a><em> </em>and identify the letters and colors using deep learning models for the suggestion of the next word.</h4><figure><img alt="Example of a wordle which I played." src="https://cdn-images-1.medium.com/max/351/1*TDRvC-3dMdwUuaAkIK2I0Q.jpeg" /><figcaption>How I played Wordle 231 — <a href="https://www.powerlanguage.co.uk/wordle/">https://www.powerlanguage.co.uk/wordle/</a></figcaption></figure><h3>Introduction</h3><figure><img alt="How to play a wordle." src="https://cdn-images-1.medium.com/max/478/1*ggM6Xbe5A_My4F4cuCzl9A.png" /><figcaption>HOW TO PLAY — <a href="https://www.powerlanguage.co.uk/wordle/">https://www.powerlanguage.co.uk/wordle/</a></figcaption></figure><p>I started playing this new trending game called Wordle and competed with family and friends with mixed luck.</p><p>Out of academic interest, I wanted to create a program that would use a snapshot of a partially-filled Wordle to automatically play the next best word for me.</p><p>Here are the steps to create a program that will analyze the screenshot, find out the letters and the colors in each square containing a letter and then return the next best word to play.</p><h3>Steps</h3><ol><li><a href="#960b">Using contour detection to separate all letters used in the Wordle</a></li><li><a href="#b444">Creating a handwritten alphabet classifier using TensorFlow Keras</a></li><li><a href="#f2ea">Creating a grey-yellow-green color classifier using TensorFlow Keras</a></li><li><a href="#4ebf">Combining contour detection and the two models to display words used in a partially-filled Wordle</a></li><li><a href="#172b">Using greedy algorithm to predict the next best word for the partially-filled Wordle</a>(future work)</li></ol><h3>Using Contour Detection to Separate All Letters Used in the Wordle</h3><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/d1b137e1865e19f333ce813e756e98df/href">https://medium.com/media/d1b137e1865e19f333ce813e756e98df/href</a></iframe><p>Place the screenshot of an image (jpg, jpeg, png, etc) into the same directory containing the <a href="#3d39">above code</a>.<br>In<em> lines 7–15</em>, the image is <strong>preprocessed </strong>so that the contours of each square-containing alphabet are produced.<br>These are the<strong> </strong>steps for preprocessing the <a href="#e7eb">original image</a>:</p><ol><li>Grayscaling the image.</li></ol><figure><img alt="" src="https://cdn-images-1.medium.com/max/412/1*4GsfvNgkhnZQY3gpl3FZqA.png" /><figcaption>Applying grayscale on the image</figcaption></figure><p>2. Sharpening the image — the kernel used sharpens all the edges found in the image, hence, it will help detect contours.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/412/1*VU6jR4IWx1SFzokJrwLMRw.png" /><figcaption>Sharpening the edges found in the Image</figcaption></figure><p>3. Thresholding the image — Converts all colors below the pixel value 225 to 255 and then inverts the image in <em>line 18 — </em>cv2.THRESH_BINARY_INV.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/412/1*n1KmkxpLjkWQOy-aOm7PHA.png" /><figcaption>Applying the threshold on the image</figcaption></figure><p>In <em>line 18</em>, you detect all those contours using <a href="https://docs.opencv.org/4.x/d4/d73/tutorial_py_contours_begin.html">cv2.findContours</a> on the thresholded image. Each contour is a <a href="https://numpy.org/doc/stable/reference/generated/numpy.array.html">NumPy array </a>of (x, y) coordinates of boundary points of the object.<br>From lines <em>29–32</em>, I find the coordinates and height and width — x,y,w,h = cv2.boundingRect(c). <br>Then I go through each contour and essentially crop the image — ROI = image[y:y+h, x:x+w] — to every contour using its coordinates(x, y) and height(h) and width(w).<br>The contour is then saved as an image in the directory — cv2.imwrite(‘ROI_{}.png’.format(image_number), ROI).</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/568/1*Iyr2aMfyk4mEpwoYy38BSQ.png" /><figcaption>How each square-containing alphabet is stored in the directory</figcaption></figure><h3>Using a Handwritten Alphabet Classifier Using TensorFlow Keras</h3><p>I could go into the details on how to code a model that would classify alphabets in TensorFlow, however, I would make another post to address this topic.<br>To save our time, I used a pre-saved model on <a href="https://www.kaggle.com/yairhadad1/cnn-for-handwritten-alphabets/data">Kaggle</a>.<br>In this case(Wordle letters’ prediction), the model is not working at its full capacity as there are no handwritten alphabets, however, for future use, this model can classify any alphabet independent of its font/style.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*evlAtF532LETVnKWtYDXEg.png" /><figcaption>Screenshot of Kaggle Webpage — <a href="https://www.kaggle.com/yairhadad1/cnn-for-handwritten-alphabets/data?select=my_model.h5">https://www.kaggle.com/yairhadad1/cnn-for-handwritten-alphabets/data?select=my_model.h5</a></figcaption></figure><p>Click on <strong>Download All</strong> and save <strong>my_model.h5</strong> into the directory.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/816465cef558e87fc7106e8c19967679/href">https://medium.com/media/816465cef558e87fc7106e8c19967679/href</a></iframe><p>In <em>line 6 </em>you load the model.<br><em>Lines 10–14 </em>display a function called crop_center which crops the center of each square-containing letter so that the letter is at an adequate size for the model for more accurate predictions.<br><em>Lines 17–43 </em>display the predict_alphabet function which predicts the alphabet. <br>Each contour is converted to a grayscale image and then thresholded as shown in <em>lines 22–23. <br></em>The image is then passed through the crop_center function. The returned image is then preprocessed in <em>lines 32–27. <br></em>The preprocessed image then becomes the input to the model and the model returns a list containing <strong>26</strong> probabilities for each letter and the index of the highest probability is found in <em>lines 40–41</em>.<br>The alphabets_mapperdictionary is then used to find the corresponding letter for the resultant index pred.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/373/1*kH8CJ8ARxlQhMLqxIH7yFA.png" /><figcaption>Flowchart of how each letter is predicted.</figcaption></figure><h3>Creating a Grey-Yellow-Green Color Classifier Using TensorFlow Keras</h3><p>The next word in a Wordle is solely influenced by the colors of all the previous letters used.<br>Creating the model to classify the three colors was surprisingly the easiest part of this project.<br>We know that each square-containing letter contains a solid color (grey, yellow or green) — a 68x68 square-containing letter image consists of 4624 RGB NumPy arrays. An RGB NumPy array has three values corresponding to red, green, and blue respectively. <br>All I did was take the first RGB value of each square-containing letter image and created a neural network using that value as my training data.<br>For example, if ROI is the variable storing a square-containing letter image, then, RGB = (np.asarray(ROI)[0][0]) will store a NumPy list such as [127 124 119] and this RGB value comes from the color grey. Similarly, a particular green-colored square-containing letter produces the first RGB value as [123 179 127] .<br>As you can see for the green RGB array, the value in the middle, corresponding to the color green “179” was higher compared to the other values in that list. Whereas in the grey RGB array, all three values were somewhat close to each other. This is what we want our model to learn and predict — using the RGB NumPy array — the color of the square-containing letter.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e503e0c72b4a8feeea3a873ac2705d1b/href">https://medium.com/media/e503e0c72b4a8feeea3a873ac2705d1b/href</a></iframe><p>Each training data in <em>line 9 </em>is an RGB NumPy array and the corresponding Y value or validation data is an integer (0, 1, 2) which acts as a key to different colors in <em>line 12.<br></em>We create the model in <em>line 15 </em>with softmax as the activation function(always the preferred activation function for multi-classification) and use sparse_categorical_crossentropyas the loss function. This loss function is best used when the validation data is integer-coded.<br>We fit the model in <em>line 21 </em>and save the model.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/647/1*R9tZxr41ThgmK1rkcWSqYA.png" /><figcaption>Simple network architecture for our neural network</figcaption></figure><p>Now we need to predict the color of each square-containing letter.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/b28cd3d932102668beaf2e08626e0bcb/href">https://medium.com/media/b28cd3d932102668beaf2e08626e0bcb/href</a></iframe><p>We load the model in <em>line 6 </em>and the first RGB NumPy array is stored in a variable called RGB in line 11.<br>From <em>lines 12–15 </em>we predict the color using that NumPy array and return the color at the end of the function.</p><h3>Combining Contour Detection and the Two Models to Display Words Used in Partially-Filled Wordle</h3><p>We have finally finished all the components of this project.</p><iframe src="" width="0" height="0" frameborder="0" scrolling="no"><a href="https://medium.com/media/e4aba9b066898b498fe58ab2a40c3ef4/href">https://medium.com/media/e4aba9b066898b498fe58ab2a40c3ef4/href</a></iframe><p>Lines 1–5, we import all libraries<br>Lines 7–35, we create crop_centerand predict_alphabet functions for predicting the alphabet in each square-containing letter.<br>Lines 37–45, we create predict_color function to predict the color of each square-containing letter.<br>Lines 70–85, we go through each contour and call functions and append the predicted letters into a list called lettersin line 80. We print the letter and the color with its RGB input on line 82.<br>Lines 88–93, we print out the words used in the Wordle.</p><p>The final output of our program using the <a href="#e7eb">Wordle</a>:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/310/1*2frw37P9hhp8NbFpBWcn0w.png" /><figcaption>Output of our program</figcaption></figure><h3>Using Greedy Algorithm to Predict the Next Best Word for the Partially-Filled Wordle</h3><p>In this post, I focused on converting the Wordle to a Python Shell output format by predicting letters and colors using my knowledge of computer vision.<br>I will leave the task of finding the next best word for the Wordle in a post which I will post soon and link here on this page.</p><p><em>More content at </em><a href="https://plainenglish.io/"><strong><em>PlainEnglish.io</em></strong></a><em>. Sign up for our </em><a href="http://newsletter.plainenglish.io/"><strong><em>free weekly newsletter</em></strong></a><em>. Follow us on </em><a href="https://twitter.com/inPlainEngHQ"><strong><em>Twitter</em></strong></a><em> and </em><a href="https://www.linkedin.com/company/inplainenglish/"><strong><em>LinkedIn</em></strong></a><em>. Join our </em><a href="https://discord.gg/GtDtUAvyhW"><strong><em>community Discord</em></strong></a><em>.</em></p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=a84010de92b7" width="1" height="1" alt=""><hr><p><a href="https://python.plainenglish.io/automating-game-wordle-using-computer-vision-a84010de92b7">Automating the Game Wordle Using Computer Vision</a> was originally published in <a href="https://python.plainenglish.io">Python in Plain English</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>
